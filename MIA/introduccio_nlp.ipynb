{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduccio a a NLP amb Pytorch\n",
    "\n",
    "**Assignatura**: Models d'intel·ligència artificial\n",
    "\n",
    "**Professor** : Ramon Mateo Navarro\n",
    "\n",
    "En aquest notebook aprendrem algunes de les bases del NLP. En el següent encara profunditzarem més en aquesta tasca.\n",
    "\n",
    "Aquest tutorial està basat en el de Microsoft learns el qual s'ha adaptat per aquest curs i els vostres coneixements. Podeu trobar el tutorial en aquest [Link](https://learn.microsoft.com/es-es/training/modules/intro-natural-language-processing-pytorch/2-represent-text-as-tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requisits\n",
    "\n",
    "Primer de tot instal·larem les llibreries essencials per poder fer això. En el següent .txt s'han recopilat les més importants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.18.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchtext) (4.66.2)\n",
      "Requirement already satisfied: requests in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchtext) (2.31.0)\n",
      "Collecting torch>=2.3.0 (from torchtext)\n",
      "  Downloading torch-2.3.0-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchtext) (1.26.3)\n",
      "Collecting filelock (from torch>=2.3.0->torchtext)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.3.0->torchtext) (4.9.0)\n",
      "Collecting sympy (from torch>=2.3.0->torchtext)\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.3.0->torchtext) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.3.0->torchtext) (3.1.3)\n",
      "Collecting fsspec (from torch>=2.3.0->torchtext)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch>=2.3.0->torchtext)\n",
      "  Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchtext) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchtext) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchtext) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchtext) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->torchtext) (0.4.6)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch>=2.3.0->torchtext)\n",
      "  Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch>=2.3.0->torchtext)\n",
      "  Downloading tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.5)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=2.3.0->torchtext)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torchtext-0.18.0-cp311-cp311-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.4/1.9 MB 12.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 24.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 24.9 MB/s eta 0:00:00\n",
      "Downloading torch-2.3.0-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "   ---------------------------------------- 0.0/159.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.3/159.8 MB 74.7 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 5.0/159.8 MB 64.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 8.4/159.8 MB 66.9 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 11.8/159.8 MB 72.6 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 14.9/159.8 MB 72.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 16.0/159.8 MB 65.6 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 16.3/159.8 MB 50.4 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 17.9/159.8 MB 43.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 21.1/159.8 MB 40.9 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 24.2/159.8 MB 43.5 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 27.3/159.8 MB 65.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 30.4/159.8 MB 73.1 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 33.0/159.8 MB 65.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 36.1/159.8 MB 65.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 39.1/159.8 MB 65.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 41.6/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 44.0/159.8 MB 65.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 47.0/159.8 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 50.1/159.8 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 53.1/159.8 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 55.1/159.8 MB 65.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 57.6/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 60.7/159.8 MB 59.8 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 63.7/159.8 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 66.7/159.8 MB 73.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 69.9/159.8 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 72.2/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 75.3/159.8 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 78.5/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 81.4/159.8 MB 65.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 83.8/159.8 MB 65.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 86.6/159.8 MB 65.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 89.4/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 92.3/159.8 MB 59.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 95.6/159.8 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 98.5/159.8 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------ -------------- 101.5/159.8 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------------- ------------- 104.7/159.8 MB 73.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 107.8/159.8 MB 73.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 110.3/159.8 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 112.9/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 115.9/159.8 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 118.1/159.8 MB 54.4 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 121.3/159.8 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 124.0/159.8 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 126.8/159.8 MB 65.2 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 127.1/159.8 MB 54.4 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 127.2/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 127.4/159.8 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 127.6/159.8 MB 31.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 128.6/159.8 MB 28.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 131.2/159.8 MB 28.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 134.4/159.8 MB 28.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 137.8/159.8 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 140.1/159.8 MB 65.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 142.5/159.8 MB 59.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 145.6/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 148.3/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 148.9/159.8 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 151.4/159.8 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 154.5/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  157.5/159.8 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 159.8/159.8 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "   ---------------------------------------- 0.0/228.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/228.5 MB 56.0 MB/s eta 0:00:05\n",
      "    --------------------------------------- 5.1/228.5 MB 65.6 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 8.2/228.5 MB 65.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 11.4/228.5 MB 65.6 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 14.4/228.5 MB 65.6 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 17.3/228.5 MB 65.6 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 20.3/228.5 MB 65.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 23.8/228.5 MB 65.2 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 26.9/228.5 MB 65.6 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 30.4/228.5 MB 73.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 33.8/228.5 MB 73.1 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 36.2/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 39.7/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 43.1/228.5 MB 72.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 46.5/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 49.5/228.5 MB 72.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 52.4/228.5 MB 73.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 55.0/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 57.9/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 61.1/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 64.1/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 65.2/228.5 MB 65.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 65.3/228.5 MB 46.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 65.6/228.5 MB 40.9 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 67.0/228.5 MB 36.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 69.7/228.5 MB 36.3 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 72.3/228.5 MB 36.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 75.2/228.5 MB 36.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 78.2/228.5 MB 65.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 81.2/228.5 MB 65.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 84.2/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 87.3/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 90.1/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 93.0/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 96.2/228.5 MB 65.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 98.5/228.5 MB 59.5 MB/s eta 0:00:03\n",
      "   ----------------- --------------------- 100.9/228.5 MB 54.4 MB/s eta 0:00:03\n",
      "   ----------------- --------------------- 104.1/228.5 MB 59.5 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 107.5/228.5 MB 59.8 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 110.6/228.5 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 113.5/228.5 MB 72.6 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 116.8/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 120.0/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 123.0/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 126.4/228.5 MB 65.2 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 129.5/228.5 MB 65.2 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 132.7/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 135.8/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 137.3/228.5 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 140.3/228.5 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 143.3/228.5 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 146.5/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 149.8/228.5 MB 65.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 152.8/228.5 MB 65.2 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 155.7/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 158.9/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 162.0/228.5 MB 65.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 165.3/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 168.2/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 171.4/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 174.6/228.5 MB 65.2 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 177.8/228.5 MB 65.2 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 180.2/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 183.4/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 186.6/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 189.9/228.5 MB 73.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 193.4/228.5 MB 73.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 196.6/228.5 MB 73.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 200.0/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 203.1/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 206.2/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 209.8/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 213.2/228.5 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 216.5/228.5 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 219.9/228.5 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 222.5/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  225.1/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.2/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 228.5/228.5 MB 21.1 MB/s eta 0:00:00\n",
      "Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/3.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/3.5 MB 2.8 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.2/3.5 MB 1.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.3/3.5 MB 1.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.5/3.5 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.0/3.5 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.5/3.5 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.4/286.4 kB ? eta 0:00:00\n",
      "Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "   ---------------------------------------- 0.0/172.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 172.0/172.0 kB ? eta 0:00:00\n",
      "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "   ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 2.7/5.7 MB 86.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.7/5.7 MB 73.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.7/5.7 MB 61.6 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 32.9 MB/s eta 0:00:00\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, sympy, mkl, fsspec, filelock, torch, torchtext\n",
      "Successfully installed filelock-3.14.0 fsspec-2024.3.1 intel-openmp-2021.4.0 mkl-2021.4.0 mpmath-1.3.0 sympy-1.12 tbb-2021.12.0 torch-2.3.0 torchtext-0.18.0\n",
      "Collecting torchdata\n",
      "  Downloading torchdata-0.7.1-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: urllib3>=1.25 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchdata) (2.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchdata) (2.31.0)\n",
      "Requirement already satisfied: torch>=2 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchdata) (2.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2->torchdata) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2->torchdata) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2->torchdata) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2->torchdata) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2->torchdata) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2->torchdata) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2->torchdata) (2021.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchdata) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchdata) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torchdata) (2024.2.2)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2->torchdata) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2->torchdata) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=2->torchdata) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
      "Downloading torchdata-0.7.1-cp311-cp311-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.3 MB 1.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.3/1.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 10.6 MB/s eta 0:00:00\n",
      "Installing collected packages: torchdata\n",
      "Successfully installed torchdata-0.7.1\n",
      "Collecting gensim==3.8.3 (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 1))\n",
      "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
      "     ---------------------------------------- 0.0/23.4 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/23.4 MB 330.3 kB/s eta 0:01:11\n",
      "     ---------------------------------------- 0.1/23.4 MB 1.6 MB/s eta 0:00:15\n",
      "     -- ------------------------------------- 1.3/23.4 MB 10.2 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 4.0/23.4 MB 23.0 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 7.1/23.4 MB 32.3 MB/s eta 0:00:01\n",
      "     ----------------- --------------------- 10.3/23.4 MB 54.7 MB/s eta 0:00:01\n",
      "     ---------------------- ---------------- 13.7/23.4 MB 73.1 MB/s eta 0:00:01\n",
      "     ---------------------- ---------------- 13.8/23.4 MB 73.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 19.3/23.4 MB 65.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 22.7/23.4 MB 65.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 23.4/23.4 MB 54.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting huggingface==0.0.1 (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 2))\n",
      "  Downloading huggingface-0.0.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rmate\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (3.8.2)\n",
      "Collecting nltk==3.5 (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4))\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "     ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.4/1.4 MB 45.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting numpy==1.18.5 (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 5))\n",
      "  Downloading numpy-1.18.5.zip (5.4 MB)\n",
      "     ---------------------------------------- 0.0/5.4 MB ? eta -:--:--\n",
      "     ----------------- ---------------------- 2.4/5.4 MB 51.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 4.9/5.4 MB 51.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.4/5.4 MB 43.5 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [92 lines of output]\n",
      "      Running from numpy source directory.\n",
      "      <string>:461: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates\n",
      "      Cythonizing sources\n",
      "      Processing numpy/random\\_bounded_integers.pxd.in\n",
      "      Processing numpy/random\\mtrand.pyx\n",
      "      C:\\Users\\rmate\\AppData\\Local\\Temp\\pip-install-ymrrvrsq\\numpy_5bb7d5debdb44f5c9a67930d3e05be30\\tools\\cythonize.py:75: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "        required_version = LooseVersion('0.29.14')\n",
      "      C:\\Users\\rmate\\AppData\\Local\\Temp\\pip-install-ymrrvrsq\\numpy_5bb7d5debdb44f5c9a67930d3e05be30\\tools\\cythonize.py:77: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "        if LooseVersion(cython_version) < required_version:\n",
      "      Processing numpy/random\\_bit_generator.pyx\n",
      "      Processing numpy/random\\_bounded_integers.pyx.in\n",
      "      Processing numpy/random\\_common.pyx\n",
      "      performance hint: _common.pyx:261:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:285:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:308:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:411:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:448:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:490:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:573:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:577:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:581:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:585:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:617:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:652:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:687:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:727:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:756:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:874:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:878:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:882:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:887:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:891:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:895:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:930:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      performance hint: _common.pyx:972:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "      Processing numpy/random\\_generator.pyx\n",
      "      performance hint: _generator.pyx:811:41: Exception check after calling '_shuffle_int' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_shuffle_int' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_shuffle_int' to allow an error code to be returned.\n",
      "      performance hint: _generator.pyx:840:45: Exception check after calling '_shuffle_int' will always require the GIL to be acquired.\n",
      "      Possible solutions:\n",
      "          1. Declare '_shuffle_int' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions.\n",
      "          2. Use an 'int' return type on '_shuffle_int' to allow an error code to be returned.\n",
      "      Processing numpy/random\\_mt19937.pyx\n",
      "      \n",
      "      Error compiling Cython file:\n",
      "      ------------------------------------------------------------\n",
      "      ...\n",
      "              for i in range(1, RK_STATE_LEN):\n",
      "                  self.rng_state.key[i] = val[i]\n",
      "              self.rng_state.pos = i\n",
      "      \n",
      "              self._bitgen.state = &self.rng_state\n",
      "              self._bitgen.next_uint64 = &mt19937_uint64\n",
      "                                         ^\n",
      "      ------------------------------------------------------------\n",
      "      \n",
      "      _mt19937.pyx:138:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned.\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\rmate\\AppData\\Local\\Temp\\pip-install-ymrrvrsq\\numpy_5bb7d5debdb44f5c9a67930d3e05be30\\tools\\cythonize.py\", line 238, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\rmate\\AppData\\Local\\Temp\\pip-install-ymrrvrsq\\numpy_5bb7d5debdb44f5c9a67930d3e05be30\\tools\\cythonize.py\", line 234, in main\n",
      "          find_process_files(root_dir)\n",
      "        File \"C:\\Users\\rmate\\AppData\\Local\\Temp\\pip-install-ymrrvrsq\\numpy_5bb7d5debdb44f5c9a67930d3e05be30\\tools\\cythonize.py\", line 225, in find_process_files\n",
      "          process(root_dir, fromfile, tofile, function, hash_db)\n",
      "        File \"C:\\Users\\rmate\\AppData\\Local\\Temp\\pip-install-ymrrvrsq\\numpy_5bb7d5debdb44f5c9a67930d3e05be30\\tools\\cythonize.py\", line 191, in process\n",
      "          processor_function(fromfile, tofile)\n",
      "        File \"C:\\Users\\rmate\\AppData\\Local\\Temp\\pip-install-ymrrvrsq\\numpy_5bb7d5debdb44f5c9a67930d3e05be30\\tools\\cythonize.py\", line 80, in process_pyx\n",
      "          subprocess.check_call(\n",
      "        File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py\", line 413, in check_call\n",
      "          raise CalledProcessError(retcode, cmd)\n",
      "      subprocess.CalledProcessError: Command '['C:\\\\Users\\\\rmate\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\python.exe', '-m', 'cython', '-3', '--fast-fail', '-o', '_mt19937.c', '_mt19937.pyx']' returned non-zero exit status 1.\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\rmate\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\rmate\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\rmate\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 149, in prepare_metadata_for_build_wheel\n",
      "          return hook(metadata_directory, config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\rmate\\AppData\\Local\\Temp\\pip-build-env-m01pro77\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 366, in prepare_metadata_for_build_wheel\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\rmate\\AppData\\Local\\Temp\\pip-build-env-m01pro77\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 487, in run_setup\n",
      "          super().run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\rmate\\AppData\\Local\\Temp\\pip-build-env-m01pro77\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 488, in <module>\n",
      "        File \"<string>\", line 469, in setup_package\n",
      "        File \"<string>\", line 275, in generate_cython\n",
      "      RuntimeError: Running cythonize failed!\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install portalocker>=2.0.0\n",
    "!pip install torchtext\n",
    "!pip install torchdata\n",
    "!pip install -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest notebook, començarem amb una senzilla tasca de classificació de text basada en el conjunt de dades de mostra ***AG.NEWS***, que consisteix a classificar els titulars de notícies en una de les 4 categories: .World, Sports, Business i Sci/Tech... Aquest conjunt de dades es construeix a partir del mòdul ``torchtext``. de ``PyTorch``, de manera que podem accedir-hi fàcilment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import os\n",
    "import collections\n",
    "torch.utils.data.datapipes.utils.common.DILL_AVAILABLE = torch.utils._import_utils.dill_available()\n",
    "import torchdata\n",
    "import torchtext.datasets\n",
    "os.makedirs('./data',exist_ok=True)\n",
    "train_dataset, test_dataset = torchtext.datasets.AG_NEWS(root='./data')\n",
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podeu observar com hem creat un directori que es dirà data on guardarem allà el dataset. Després hem creat una llista on tindrem els .\n",
    "\n",
    "Aquí, trainsetdataset i test_dataset contenen iterators que retornen parells d'etiqueta (nombre de classe) i text respectivament, per exemple:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o iterant..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in zip(range(5),train_dataset):\n",
    "    print(f\"**{classes[x[0]]}** -> {x[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Així que com ara el volem fer servir diverses vegades per tal de fer-ho més fàcil ho transformarem en una llista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torchtext.datasets.AG_NEWS(root='./data')\n",
    "train_dataset = list(train_dataset)\n",
    "test_dataset = list(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenització i vectorització\n",
    "\n",
    "Ara necessitem convertir text en **números** que es puguin representar com a tensors per alimentar-los en una xarxa neuronal. El primer pas és convertir text a tokens - *tokenization**. Si utilitzem la representació a nivell de paraula, cada paraula estaria representada pel seu propi token. Utilitzarem el tokenizer integrat des del mòdul ``torchtext``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilitzarem el tokenizer de PyTorch per dividir paraules i espais en els primers 2 articles de notícies. En el nostre cas, utilitzem BASIC forenglish per al tokenizer per entendre l'estructura del llenguatge. Això retornarà una llista de cadenes del text i els caràcters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sentence = train_dataset[0][1]\n",
    "second_sentence = train_dataset[1][1]\n",
    "\n",
    "f_tokens = tokenizer(first_sentence)\n",
    "s_tokens = tokenizer(second_sentence)\n",
    "\n",
    "print(f'\\nfirst token list:\\n{f_tokens}')\n",
    "print(f'\\nsecond token list:\\n{s_tokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "\n",
    "Abans de proseguir fem una petita pausa i anem a entendre un concepte que està molt relacionat aqui, els **word embeddings**. \n",
    "\n",
    "Els \"word embeddings\" o incrustacions de paraules són una tècnica utilitzada en el processament del llenguatge natural per representar les paraules en forma de vectors de números. La idea bàsica és transformar cada paraula en un vector dens que captura informació sobre el seu significat i el context en què sol aparèixer. Aquests vectors són creats de manera que les paraules que tenen significats similars o que s'utilitzen en contextos similars estiguin representades per vectors que estan propers entre si en l'espai vectorial.\n",
    "\n",
    "**Com funcionen?** \n",
    "\n",
    "Quan es crea un \"word embedding\", el model aprendrà a assignar vectors a les paraules de manera que la distància entre els vectors reflecteixi les relacions semàntiques i sintàctiques entre les paraules. Això s'aconsegueix mitjançant el entrenament en un gran corpus de text, on el model utilitza el context d'una paraula (les paraules que l'envolten) per predir la paraula mateixa.\n",
    "\n",
    "**Per què són útils?**\n",
    "* **Reducció de la Dimensionalitat**: Convertir paraules en vectors compactes redueix la complexitat i facilita el maneig computacional.\n",
    "* **Similitud Semàntica**: Permet als models de NLP detectar similituds semàntiques entre paraules, millorant així la qualitat de tasques com la cerca de text, la classificació de text i més.\n",
    "* **Flexibilitat**: Poden ser utilitzats en una varietat d'aplicacions de NLP, des de sistemes de resposta automàtica fins a anàlisi de sentiments.\n",
    "\n",
    "![](images_lab_nlp\\word_embeddings_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuació, per convertir text a números, necessitarem construir un vocabulari de tots els tokens. Primer construïm el diccionari utilitzant l'objecte ``Counter`` i després creem un objecte ``Vocab`` que ens ajudaria a fer front a la vectorització:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = collections.Counter()\n",
    "for (label, line) in train_dataset:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = torchtext.vocab.Vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per veure com cada paraula s'assigna al vocabulari, farem un bucle a través de cada paraula de la llista per cercar el seu número d'índex en ``vocab``. Cada paraula o caràcter es mostra amb l'índex corresponent. Per exemple, la paraula ``the`` apareix diverses vegades en ambdues frases i és un índex únic en el vocab és el nombre **3**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lookup = [list((vocab[w], w)) for w in f_tokens]\n",
    "print(f'\\nIndex lockup in 1st sentence:\\n{word_lookup}')\n",
    "\n",
    "word_lookup = [list((vocab[w], w)) for w in s_tokens]\n",
    "print(f'\\nIndex lockup in 2nd sentence:\\n{word_lookup}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilitzant vocabulari, podem codificar fàcilment la nostra cadena tokenitzada en un conjunt de nombres. Fem servir el primer article de notícies com a exemple:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(f\"Vocab size if {vocab_size}\")\n",
    "\n",
    "def encode(x):\n",
    "    return [vocab.stoi[s] for s in tokenizer(x)]\n",
    "\n",
    "vec = encode(first_sentence)\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest codi, el diccionari torchtext ``vocab.stoi``. ens permet convertir des d'una representació de cadena en números (el nom stoi* significa \"des de *s**tring *a** *i**ntegers). Per a tornar a convertir el text d'una representació numèrica en text, podem utilitzar el diccionari ``vocab.itos`` per a realitzar una cerca inversa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
