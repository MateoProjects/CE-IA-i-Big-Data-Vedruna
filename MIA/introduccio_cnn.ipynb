{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducció a las Xarxes neuronals convolucionals\n",
    "\n",
    "**Assignatura**: Models d'intel·ligència artificial\n",
    "\n",
    "**Professor** : Ramon Mateo Navarro\n",
    "<p style=\"text-align: justify;\">\n",
    "\n",
    "En aquest notebook farem una introducció a les xarxes neuronals convolucionals. Aprendrem les bases per crear la nostra primera xarxa neuronal convolucional fent servir diferents datasets i explorarem els problemes que presenta grans volums de dades.\n",
    "</p>\n",
    "\n",
    "## Recordem:\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "\n",
    "Les xarxes neuronals convolucionals (CNN) utilitzen l'operació matemàtica de convolució. Aquesta operació es realitza amb un kernel, que és una matriu de dimensions n x m, i el conjunt de tots els kernels es denomina filtres.\n",
    "\n",
    "L'operació de convolució consisteix en calcular el producte puntual entre el kernel i una regió corresponent de l'imatge d'entrada, i després sumar tots els resultats d'aquests productes. Aquest procés es realitza a través de la imatge aplicant el mateix kernel en diferents ubicacions, produint una imatge convolucionada com a resultat.\n",
    "</p>\n",
    "\n",
    "![](images_lab3\\convolucio.gif)\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "\n",
    "Per reduir les dimensions de la imatge resultant en una xarxa neuronal convolucional, es poden aplicar tècniques com el max pooling, l'average pooling i altres tècniques de pooling. Aquestes capes de pooling redueixen la mida espacial (alçada i amplada) de la imatge mantenint només la informació més rellevant. En el cas del max pooling, es conserva el valor màxim de cada regió, mentre que en l'average pooling es calcula el valor promig. Aquestes tècniques ajuden a reduir el nombre de paràmetres a la xarxa i a augmentar la invariància a petites traslaciones en l'entrada.\n",
    "</p>\n",
    "\n",
    "\n",
    "![](images_lab3\\max_avg.gif)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Per aquest exercici farem servir tensorflow i keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tensorflow.keras import datasets, layers, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega i visualització del dataset\n",
    "\n",
    "Per aquest primer exercici farem servir el dataset CIFAR10 que conté 60.000 imatges. sis mil imatges per cada classe (en total 10 classes diferents).\n",
    "\n",
    "Link del dataset: [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "A recordar:\n",
    "* Recordem que les imatges es componen de tres canals RGB. Un per cada color. \n",
    "* Que normalitzar valors ajuda el model a ser entrenat millor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualitzem el dataset per veure com son les imatges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definició del model\n",
    "\n",
    "Anteriorment, ja hem vist com declarar un model amb tensorflow/keras. Farem ara exactament el mateix però fent servir les capes de convolució 2D i les de pooling. \n",
    "\n",
    "**Nota**: Les capes de convolució 2D s'utilitzen quan es vol processar una única imatge en cada moment. Per a l'anàlisi de vídeos, que requereix considerar la dimensió temporal a més de les espacials, cal fer servir capes de convolució 3D.\n",
    "\n",
    "Links: \n",
    "* Capa de convolució: [Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "* Capa de maxpooling: [MaxPooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPooling2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilació i entrenament del model\n",
    "\n",
    "Per aquest entrenament farem servir l'optimitzador Adam, com a funció de pèrdua farem servir la Sparse Categorical Cross Entropy que ja s'ha explicat anteriorment.\n",
    "\n",
    "Fixeu-vos que afegim un dataset de validació que són les imatges de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, batch_size=16, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluant el model\n",
    "\n",
    "Anem analitzar l'entranment del model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predint noves imatges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "image = np.expand_dims(test_images[idx], axis=0)\n",
    "prediction = np.argmax(model.predict(image))\n",
    "print(\"Value predicted\", class_names[prediction], \"\\nValue expected:\", class_names[test_labels[idx][0]])\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasques:\n",
    "\n",
    "* Mireu que succeix quan modifiqueu el batchsize així com el número de epochs.\n",
    "* Proveu d'afegir noves capes.\n",
    "* Descarregueu aquest dataset i proveu de crear el vostre model de classificació (farem el preprocessament junts): [Pokemon Dataset](https://www.kaggle.com/datasets/vishalsubbiah/pokemon-images-and-types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessant el nou dataset\n",
    "\n",
    "Si observem veurem que tenim la categoria (el tipus i el que volem arribar a predir) en format categòric. Recordem que un model no sap predir variables categòriques sinó numèriques. Per tant, haurem de transformar aquestes dades a valors numèrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset lab3\\pokemon.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anem primer de tot eliminar les columnes que no volem, en aquest exercici ens centrarem només a intentar predir el tipus 1 del pokemon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Type2', 'Evolution'], axis='columns')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anem a transformar ara type1 en valors numèrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipus = pd.get_dummies(data.Type1)\n",
    "tipus.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixeu-vos com ara totes tenen tot a false menys una columna que està a true que representa el valor que són.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregant imatges\n",
    "\n",
    "Ara toca carregar les imatges, fixeu-vos que tots els Pokémon tenen el seu nom ben indicat i el tipus. El que podem fer és per cada fila del dataset carregar la imatge corresponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images = list()\n",
    "\n",
    "for row in data.iterrows():\n",
    "    image = cv2.imread('dataset_lab3\\\\images\\\\' + row[1][0] + '.png')\n",
    "    image = cv2.resize(image, (64,64))\n",
    "    total_images.append(image)\n",
    "\n",
    "total_images = np.array(total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
