{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduccio a Pytorch\n",
    "\n",
    "**Assignatura**: Models d'intel·ligència artificial\n",
    "\n",
    "**Professor** : Ramon Mateo Navarro\n",
    "\n",
    "En aquest notebook farem una introducció a Pytorch. Aprendrem les bases per crear la nostra primera xarxa neuronal fent servir el dataset MNIST però aquest cop amb Pytorch. Farem servir també comandes per fer ús de la GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instal·lació \n",
    "\n",
    "Primer de tot hem d'instal·lar els paquets necessaris. Començarem instal·lant Pytorch i Pytorch vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torchvision in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\rmateo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Ara importarem les llibreries. Les essencials són:\n",
    "\n",
    "* ``torch``: llibreria principal de PyTorch\n",
    "* ``torchvision``: llibreria que conté utilitats per treballar amb imatges per visió per ordinador com conjunts de dades per entrenar, models preentrenats etc...\n",
    "* ``torch.nn``: mòdul que conté classes per la construcció de xarxes neuronals\n",
    "* ``torch.optim``: mòdul que conté algoritmes d'optimització com SGD o Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importem les biblioteques necessàries\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "Un tensor és un array multidimensional, similar a un array de NumPy. Podem crear tensors amb valors específics, amb tots els valors a zero, amb tots els valors a un, o amb valors aleatoris. Similar a NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0.6306, 0.1587, 0.7163],\n",
      "        [0.4760, 0.4986, 0.4446],\n",
      "        [0.1375, 0.9243, 0.3288]])\n"
     ]
    }
   ],
   "source": [
    "# Creem un tensor amb PyTorch\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(x)\n",
    "\n",
    "# Creem una matriu de zeros amb PyTorch\n",
    "zeros = torch.zeros(3, 3)\n",
    "print(zeros)\n",
    "\n",
    "# Creem una matriu d'uns amb PyTorch\n",
    "ones = torch.ones(3, 3)\n",
    "print(ones)\n",
    "\n",
    "# Creem una matriu amb valors aleatoris\n",
    "random_matrix = torch.rand(3, 3)\n",
    "print(random_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera xarxa neuronal\n",
    "\n",
    "En PyTorch, les xarxes neuronals es defineixen com a classes que hereten de la classe base ``nn.Module``. Aquesta estructura de classe permet encapsular tots els components de la xarxa neuronal (com les capes i les funcions d'activació) en una sola entitat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe SimpleNet és una xarxa neuronal que està definida com una classe que hereta de nn.Module, que és la classe base per a totes les xarxes neuronals en PyTorch.\n",
    "\n",
    "Dins del mètode ``__init__``, primer cridem al constructor de la classe base amb ``super(SimpleNet, self).__init__()``. Això és necessari perquè PyTorch pugui fer un seguiment de totes les capes i paràmetres de la xarxa.\n",
    "\n",
    "A continuació, definim una capa totalment connectada (o lineal) amb ``self.fc1 = nn.Linear(3, 3)``. ``nn.Linear`` és una classe que representa una capa totalment connectada. Els paràmetres de ``nn.Linear`` són el nombre d'entrades i el nombre de sortides. En aquest cas, tenim 3 entrades i 3 sortides.\n",
    "\n",
    "El mètode forward defineix com es processa l'entrada a través de la xarxa. En aquest cas, simplement passem l'entrada a través de la capa fc1 amb ``x = self.fc1(x)``. La sortida d'aquesta capa es retorna com a sortida de la xarxa.\n",
    "\n",
    "En resum, aquesta xarxa neuronal consisteix en una sola capa totalment connectada que accepta 3 entrades i retorna 3 sortides. L'entrada es processa passant-la a través de la capa totalment connectada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4048, -2.2980,  0.6238], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Creem una instància de la xarxa\n",
    "net = SimpleNet()\n",
    "\n",
    "# Creem un tensor d'entrada\n",
    "input = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# Passem el tensor a través de la xarxa\n",
    "output = net(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest codi, primer creem una instància de la nostra xarxa neuronal SimpleNet. A continuació, creem un tensor d'entrada amb tres valors. Aquest tensor representa les dades d'entrada que volem passar a través de la xarxa.\n",
    "\n",
    "Finalment, passem el tensor d'entrada a través de la xarxa utilitzant la crida net(input). Això crida el mètode forward de la xarxa, que processa l'entrada a través de la capa totalment connectada. La sortida de la xarxa es imprimeix a la consola.\n",
    "\n",
    "Aquesta sortida és el resultat de passar l'entrada a través de la xarxa. En aquest cas, com que la xarxa és inicialment aleatòria (els pesos de la capa totalment connectada s'inicialitzen aleatòriament), la sortida també serà aleatòria. En un escenari real, entrenaríem la xarxa en un conjunt de dades per aprendre els pesos que minimitzen alguna funció de pèrdua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definint OPT i Loss fn\n",
    "\n",
    "Ara anirem un pas més enllà i farem servir optimitzador i funció de perdua. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3556326627731323\n"
     ]
    }
   ],
   "source": [
    "# Definim una funció de pèrdua\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Definim un optimitzador\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# Generem una sortida d'objectiu per a l'entrenament\n",
    "target = torch.tensor([0.5, -0.5, 0.5])\n",
    "\n",
    "# Realitzem un pas d'entrenament\n",
    "optimizer.zero_grad()   # posa a zero els gradients\n",
    "output = net(input)     # passa l'entrada a través de la xarxa\n",
    "loss = criterion(output, target) # calcula la pèrdua\n",
    "loss.backward()         # calcula els gradients\n",
    "optimizer.step()        # actualitza els pesos de la xarxa\n",
    "\n",
    "print(loss.item())      # imprimeix la pèrdua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquest codi mostra com es pot entrenar la xarxa neuronal. Primer, definim una funció de pèrdua i un optimitzador. La funció de pèrdua és el criteri que utilitzem per mesurar com de bé està fent la xarxa, i l'optimitzador és l'algoritme que utilitzem per ajustar els pesos de la xarxa per minimitzar la funció de pèrdua.\n",
    "\n",
    "A continuació, generem una sortida d'objectiu per a l'entrenament. Aquesta seria la sortida que voldríem que la xarxa produís quan li donem l'entrada.\n",
    "\n",
    "Després realitzem un pas d'entrenament. Primer, posem a zero els gradients de l'optimitzador. Això és necessari perquè PyTorch acumula els gradients en cada crida a backward, de manera que necessitem posar-los a zero abans de calcular-los per al següent pas.\n",
    "\n",
    "Després, passem l'entrada a través de la xarxa per obtenir la sortida, i calculem la pèrdua comparant aquesta sortida amb la sortida d'objectiu. Aquesta pèrdua és el valor que volem minimitzar.\n",
    "\n",
    "A continuació, cridem ``loss.backward()`` per calcular els gradients de la pèrdua respecte als pesos de la xarxa. Aquests gradients són utilitzats per l'optimitzador per ajustar els pesos.\n",
    "\n",
    "Finalment, cridem ``optimizer.step()`` per realitzar un pas d'optimització, que actualitza els pesos de la xarxa segons els gradients calculats.\n",
    "\n",
    "Finalment, imprimim la pèrdua per veure com de bé està fent la xarxa. Aquest valor hauria de disminuir a mesura que entrenem la xarxa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteració 0, pèrdua: 1.098062515258789\n",
      "Iteració 10, pèrdua: 0.13349880278110504\n",
      "Iteració 20, pèrdua: 0.01623033732175827\n",
      "Iteració 30, pèrdua: 0.001973232952877879\n",
      "Iteració 40, pèrdua: 0.00023989939654711634\n",
      "Iteració 50, pèrdua: 2.9166056265239604e-05\n",
      "Iteració 60, pèrdua: 3.545959771145135e-06\n",
      "Iteració 70, pèrdua: 4.311179111482488e-07\n",
      "Iteració 80, pèrdua: 5.2399542482817196e-08\n",
      "Iteració 90, pèrdua: 6.374222039084998e-09\n"
     ]
    }
   ],
   "source": [
    "# Realitzem l'entrenament durant 100 iteracions\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()   # posa a zero els gradients\n",
    "    output = net(input)     # passa l'entrada a través de la xarxa\n",
    "    loss = criterion(output, target) # calcula la pèrdua\n",
    "    loss.backward()         # calcula els gradients\n",
    "    optimizer.step()        # actualitza els pesos de la xarxa\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Iteració {i}, pèrdua: {loss.item()}\")  # imprimeix la pèrdua cada 10 iteracions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquest codi realitza el mateix procés d'entrenament que abans, però ara ho fa durant 100 iteracions. Això significa que passem l'entrada a través de la xarxa, calculem la pèrdua, calculem els gradients i actualitzem els pesos de la xarxa 100 vegades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3613, -0.0025, -0.5441], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test de la xarxa\n",
    "test_input = torch.tensor([0.5, -0.5, 0.5])\n",
    "test_output = net(test_input)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardant el model i carregant el model\n",
    "\n",
    "El següent codi mostra com es pot guardar un model entrenat a disc i després carregar-lo de nou. Això és útil si vols entrenar un model, guardar-lo i després utilitzar-lo més tard o en un altre lloc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3613, -0.0025, -0.5441], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Guardem el model entrenat\n",
    "torch.save(net.state_dict(), 'model.pth')\n",
    "\n",
    "# Carreguem el model entrenat\n",
    "loaded_net = SimpleNet()\n",
    "loaded_net.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "# Comprovem que el model carregat dona la mateixa sortida\n",
    "loaded_output = loaded_net(test_input)\n",
    "print(loaded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funció torch.save guarda els paràmetres de la xarxa (els pesos i biaixos de les capes) a un fitxer. El mètode state_dict de la xarxa retorna un diccionari que conté aquests paràmetres.\n",
    "\n",
    "Després, per carregar el model, primer creem una nova instància de la xarxa amb ``SimpleNet()``. Després utilitzem el mètode ``load_state_dict`` per carregar els paràmetres des del fitxer al model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight tensor([[-0.3750, -0.1186,  0.2491],\n",
      "        [ 0.0498, -0.2053, -0.0036],\n",
      "        [-0.5218,  0.0652,  0.4568]])\n",
      "fc1.bias tensor([ 0.3649, -0.1283, -0.4790])\n"
     ]
    }
   ],
   "source": [
    "# Visualitzem els pesos de la xarxa\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenant una xarxa amb MNIST\n",
    "\n",
    "Tornarem a fer servir ara el dataset MNIST però aquest cop per entrenar la xarxa amb PyTorch.\n",
    "\n",
    "Primer, necessitarem importar el conjunt de dades MNIST de PyTorch. També comprovarem si hi ha una GPU disponible i, si és així, prepararem el dispositiu per a la GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to C:\\Users\\rmateo/.pytorch/MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 3484237.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\rmateo/.pytorch/MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to C:\\Users\\rmateo/.pytorch/MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to C:\\Users\\rmateo/.pytorch/MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 256402.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\rmateo/.pytorch/MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to C:\\Users\\rmateo/.pytorch/MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to C:\\Users\\rmateo/.pytorch/MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 2435826.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\rmateo/.pytorch/MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to C:\\Users\\rmateo/.pytorch/MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to C:\\Users\\rmateo/.pytorch/MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Users\\rmateo/.pytorch/MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to C:\\Users\\rmateo/.pytorch/MNIST_data/MNIST\\raw\n",
      "\n",
      "Training on device cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Definim la transformació per normalitzar les dades\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Descarreguem i carreguem el conjunt de dades d'entrenament\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Comprovem si hi ha una GPU disponible\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Training on device {device}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquest codi primer defineix una transformació que convertirà les imatges a tensors i les normalitzarà. Després descarrega i carrega el conjunt de dades MNIST, que consisteix en imatges de dígits escrits a mà, i defineix un carregador de dades que ens proporcionarà lots de 64 imatges a l'hora.\n",
    "\n",
    "Després comprova si hi ha una GPU disponible utilitzant ``torch.cuda.is_available()``. Si hi ha una GPU disponible, definim el dispositiu com a 'cuda', que és el nom que PyTorch utilitza per a la GPU. Si no hi ha cap GPU disponible, definim el dispositiu com a 'cpu'. Finalment, imprimim el dispositiu en què s'entrenarà."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definint la xarxa per MNIST\n",
    "\n",
    "En PyTorch, les capes i les funcions d'activació són tractades com a mòduls separats. Això vol dir que primer es defineix la capa lineal (o convolucional, etc.) i després es defineix la funció d'activació com un pas separat. Això permet una major flexibilitat, ja que pots encadenar qualsevol nombre de mòduls en qualsevol ordre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "# Definim la xarxa neuronal\n",
    "net = nn.Sequential(nn.Linear(784, 128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(64, 10),\n",
    "                    nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Movem la xarxa a la GPU si està disponible\n",
    "net.to(device)\n",
    "\n",
    "# Definim la funció de pèrdua i l'optimitzador\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquesta xarxa té tres capes lineals intercalades amb funcions d'activació ReLU. La capa final és una funció softmax que donarà la probabilitat de cada classe.\n",
    "\n",
    "Després, movem la xarxa al dispositiu que hem definit abans (la GPU si està disponible, sinó la CPU) amb ``net.to(device)``.\n",
    "\n",
    "Finalment, definim la funció de pèrdua com la pèrdua de logaritme negatiu (una funció de pèrdua comuna per a problemes de classificació) i l'optimitzador com el descens del gradient estocàstic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenant la xarxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.897130252328763\n",
      "Training loss: 0.8672184709038562\n",
      "Training loss: 0.5320908153520972\n",
      "Training loss: 0.43386330283971736\n",
      "Training loss: 0.38834050985605223\n"
     ]
    }
   ],
   "source": [
    "# Entrenem la xarxa durant 5 èpoques\n",
    "for epoch in range(5):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Aplatem les imatges\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Movem les imatges i les etiquetes a la GPU si està disponible\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass, backward pass, and update weights\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquest codi entrena la xarxa durant 5 èpoques. En cada època, passa totes les imatges del conjunt de dades d'entrenament a través de la xarxa, calcula la pèrdua, fa la retropropagació per calcular els gradients, i actualitza els pesos amb l'optimitzador.\n",
    "\n",
    "També aplatem les imatges abans de passar-les a través de la xarxa, ja que la xarxa espera vectors d'entrada en lloc d'imatges 2D. I movem les imatges i les etiquetes a la GPU si està disponible.\n",
    "\n",
    "Finalment, imprimim la pèrdua d'entrenament mitjana per a cada època. Aquesta pèrdua hauria de disminuir amb el temps a mesura que la xarxa apren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluant el model\n",
    "\n",
    "Després d'entrenar la xarxa, voldrem avaluar el seu rendiment en un conjunt de dades de prova que no ha vist abans. Això ens donarà una bona idea de com es comportarà la xarxa en dades noves.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8949\n"
     ]
    }
   ],
   "source": [
    "# Descarreguem i carreguem el conjunt de dades de prova\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Inicialitzem el comptador de prediccions correctes\n",
    "correct_count = 0\n",
    "total_count = 0\n",
    "\n",
    "# Passem cada imatge del conjunt de dades de prova a través de la xarxa\n",
    "for images, labels in testloader:\n",
    "    # Aplatem les imatges i les movem a la GPU si està disponible\n",
    "    images = images.view(images.shape[0], -1)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    # Passem les imatges a través de la xarxa\n",
    "    output = net(images)\n",
    "\n",
    "    # Obtenim les prediccions de la xarxa\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "    # Actualitzem el comptador de prediccions correctes\n",
    "    total_count += labels.size(0)\n",
    "    correct_count += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy: {correct_count / total_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenant xarxes convolucionals amb Pytorch\n",
    "\n",
    "Ja hem vist ara les neurones, passem a les convolucionals. Coneixem ja els pasos i la classe a definir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquesta xarxa té dues capes convolucionals, seguides per una capa de max pooling, una capa de dropout per regularitzar la xarxa i evitar l'overfitting, i finalment dues capes totalment connectades (o lineals). La funció ``forward`` defineix com es processa l'entrada a través d'aquestes capes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara que tenim la nostra arquitectura de xarxa definida, el següent pas seria entrenar la nostra xarxa. Aquí tens un exemple de com fer-ho:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249d2669abb74d0688f843be40cbc414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1638, Accuracy: 94.91%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e89fa68c476490b8a1e1722651e4886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.0775, Accuracy: 97.66%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ea2b9f9e2e4e40a328065e61fe8a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.0606, Accuracy: 98.15%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43454de7ed84314accdb18e182296d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.0523, Accuracy: 98.40%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae56c473fe4544579b7181c1de33b46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.0481, Accuracy: 98.50%\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Comprovem si hi ha una GPU disponible i, si és així, la utilitzem\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Creem una instància de la nostra xarxa i l'enviem a la GPU si està disponible\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "# Definim la funció de pèrdua i l'optimitzador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Llistes per guardar les pèrdues i exactituds\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "# Entrenem la xarxa\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total = 0\n",
    "    # Afegim tqdm al bucle per mostrar una barra de progrés\n",
    "    for i, (images, labels) in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
    "        # Enviem les imatges i les etiquetes a la GPU si està disponible\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_loss /= len(trainloader)\n",
    "    train_acc = 100 * train_correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validant el model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Definim les transformacions per les imatges\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Descarreguem i carreguem el conjunt de dades de validació\n",
    "val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Definim el DataLoader de validació\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# Creem llistes per guardar les pèrdues i exactituds de validació\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "\n",
    "# Passem el model a mode d'avaluació\n",
    "model.eval()\n",
    "\n",
    "# Desactivem el càlcul del gradient perquè no necessitem actualitzar els pesos en aquesta fase\n",
    "with torch.no_grad():\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(val_loader, total=len(val_loader)):\n",
    "        # Enviem les imatges i les etiquetes a la GPU si està disponible\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        val_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = 100 * val_correct / total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
